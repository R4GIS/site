<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Regressão on Curso-R</title>
    <link>http://curso-r.com/tags/regress%C3%A3o/</link>
    <description>Recent content in Regressão on Curso-R</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <copyright>Copyright (c) 2016 - 2017, Curso-R; all rights reserved.</copyright>
    <lastBuildDate>Mon, 07 Aug 2017 10:12:00 +0300</lastBuildDate>
    
	<atom:link href="http://curso-r.com/tags/regress%C3%A3o/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Mínimos quadrados com restrições lineares</title>
      <link>http://curso-r.com/blog/2017/08/07/2017-08-07-minimos-quadrados-restrito/</link>
      <pubDate>Mon, 07 Aug 2017 10:12:00 +0300</pubDate>
      
      <guid>http://curso-r.com/blog/2017/08/07/2017-08-07-minimos-quadrados-restrito/</guid>
      <description>A característica mais importante de um modelo estatístico é a sua flexibilidade. Esse termo pode ser entendido de várias formas, mas neste texto vou considerar que um modelo é flexível se ele explica coerentemente uma ampla gama de fenômenos reais.
Pensando assim, a regressão linear pode ser considerada um modelo flexível, já que muitas relações funcionais cotidianas são do tipo \(y = \beta x\). É justamente por causa dessa flexibilidade que a boa e velha regressão de mínimos quadrados é tão usada, até mesmo aonde não deveria.</description>
    </item>
    
    <item>
      <title>Modelando a variância da normal</title>
      <link>http://curso-r.com/blog/2017/03/09/2017-02-21-regressao-heterocedastica/</link>
      <pubDate>Thu, 09 Mar 2017 13:07:31 +0200</pubDate>
      
      <guid>http://curso-r.com/blog/2017/03/09/2017-02-21-regressao-heterocedastica/</guid>
      <description>Verificar as suposições dos modelos é muito importante quando fazemos inferência estatística. Em particular, a suposição de homocedasticidade1 dos modelos de regressão linear é especialmente importante, pois modifica o cálculo de erros padrão, intervalos de confiança e valores-p.
Neste post, vou mostrar três pacotes do R que ajustam modelos da forma
\[ Y_i = \beta_0 + \sum_{k=1}^p\beta_kx_{ik} + \epsilon_i, \ i = 1,\ldots,n\]
\[ \epsilon_{i} \sim \textrm{N}(0,\sigma_i), \ i = 1,\ldots,n \ \textrm{independentes, com }\sigma_i^2 = \alpha x_i^2.</description>
    </item>
    
  </channel>
</rss>